% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/setup_pipeline.R
\name{setup_pipeline}
\alias{setup_pipeline}
\title{Setup a Pipeline Environment}
\usage{
setup_pipeline(
  pipeline_name,
  description,
  db_type = c("azure_sql", "sqlite"),
  sqlite_db_path = "local_db.sqlite",
  log_file_path = NULL
)
}
\arguments{
\item{pipeline_name}{A character string for the name of the pipeline.}

\item{description}{A brief character string describing the pipeline's purpose.}

\item{db_type}{A character string specifying the database backend.
Either `"azure_sql"` (default) or `"sqlite"`.}

\item{sqlite_db_path}{A character string path to the SQLite database file.
Only used if `db_type = "sqlite"`. Defaults to "local_db.sqlite".}

\item{log_file_path}{The path where the detailed log file should be saved.
Defaults to creating a timestamped log file in the current directory.}
}
\value{
A named list serving as the "pipeline context" object.
}
\description{
Initializes all necessary components for an ETL pipeline run. This includes
creating a metadata log, a detailed file/console logger, a database
connection, and connecting to a pins board.
}
\details{
This function relies heavily on environment variables for securely handling
credentials for production services like Azure and Posit Connect.
}
\examples{
\dontrun{
# To connect to SQLite for local development:
# First, create and seed the database using the helper script.
context_sqlite <- setup_pipeline(
  pipeline_name = "local-dev-pipeline",
  description = "A test run using the local SQLite database.",
  db_type = "sqlite"
)
DBI::dbDisconnect(context_sqlite$db_con)
}
}
